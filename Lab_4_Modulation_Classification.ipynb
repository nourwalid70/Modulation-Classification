{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nourwalid70/Modulation-Classification/blob/main/Lab_4_Modulation_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcWDJbixJ0JF"
      },
      "outputs": [],
      "source": [
        "!pip install pydub\n",
        "!pip install --upgrade tensorflow\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mhgwi5WoJ2nv"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import Conv2D, Conv1D \n",
        "from tensorflow.keras.layers import MaxPool2D, MaxPool1D\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.utils import np_utils\n",
        "from keras.metrics import SparseCategoricalAccuracy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import glob\n",
        "import librosa\n",
        "from librosa import display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle as cPickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy import integrate\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RftpA5ueC_LP",
        "outputId": "15271203-24b1-4b43-e59a-56139b9148f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/device:GPU:0']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from keras import backend as K\n",
        "K._get_available_gpus()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBupOM8ZVMh4"
      },
      "source": [
        "#Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KuXzwHaJ50v",
        "outputId": "606eab02-86ba-4453-a6ae-cf332c4b1004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm8DwNZLYYa3"
      },
      "outputs": [],
      "source": [
        "# differentiation and integration features\n",
        "def add_features(data):\n",
        "  new_data = []\n",
        "  #np.empty((0, 3*data.shape[1], data.shape[2]))\n",
        "  for sample in data:\n",
        "    # differentiation\n",
        "    #grad = np.gradient(sample, axis = 1)\n",
        "    \n",
        "    # integration\n",
        "    intg = integrate.cumtrapz(sample, initial=0)\n",
        "\n",
        "    # append data\n",
        "    new_sample = np.vstack((sample, intg))\n",
        "    new_data.append(new_sample)\n",
        "\n",
        "  return np.array(new_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM7K16sHNNrC"
      },
      "outputs": [],
      "source": [
        "x = []  \n",
        "labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd1r9VUbJ_z4"
      },
      "outputs": [],
      "source": [
        "# reading data\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/PR lab4/RML2016.10b.dat\"\n",
        "f = open(path,'rb')\n",
        "df = pd.read_pickle(path)\n",
        "snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], df.keys())))), [1,0])\n",
        "\n",
        "for mod in mods:\n",
        "    for snr in snrs:\n",
        "        x.append(df[(mod,snr)])\n",
        "        for i in range(df[(mod,snr)].shape[0]):  labels.append((mod,snr))\n",
        "x = np.vstack(x)\n",
        "labels=np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9lFUuBiyBsj"
      },
      "outputs": [],
      "source": [
        "# adding the new features\n",
        "print(x.shape)\n",
        "x = add_features(x)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-9tsBx4O59M"
      },
      "outputs": [],
      "source": [
        "#split data\n",
        "train_data, test_data, train_labels,test_labels = train_test_split(x,labels,test_size=0.3, random_state = 10, stratify = labels)\n",
        "train_data, val_data, train_labels,val_labels = train_test_split(train_data,train_labels, test_size=0.05,random_state=12, stratify=train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR24VQ3k8YWS"
      },
      "outputs": [],
      "source": [
        "#keep old test labels for big picture\n",
        "old_test_labels = test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_Q5sLUJOu6i"
      },
      "outputs": [],
      "source": [
        "# encode labels [0, .. ,9]\n",
        "label = LabelEncoder() \n",
        "train_labels= label.fit_transform(train_labels[:,0])\n",
        "test_labels= label.fit_transform(test_labels[:,0])\n",
        "val_labels= label.fit_transform(val_labels[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwwHv1Nxy2ai"
      },
      "outputs": [],
      "source": [
        "# clear unnecessary memory\n",
        "del df\n",
        "del x\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UasqP4K7Xss2"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPmm5ZSbQMIR"
      },
      "outputs": [],
      "source": [
        "train_data=train_data.reshape((train_data.shape[0],1,train_data.shape[2],train_data.shape[1]))\n",
        "test_data=test_data.reshape((test_data.shape[0],1,test_data.shape[2],test_data.shape[1]))\n",
        "val_data=val_data.reshape((val_data.shape[0],1,val_data.shape[2],val_data.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O53a0e4OrhEu",
        "outputId": "ab7424b6-8910-4b14-85ce-6fcc55798887"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((798000, 1, 128, 2), (42000, 1, 128, 2), (360000, 1, 128, 2))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.shape, val_data.shape, test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MISwb9IcVZ6b"
      },
      "outputs": [],
      "source": [
        "train_labels = to_categorical(list(train_labels))\n",
        "test_labels = to_categorical(list(test_labels))\n",
        "val_labels = to_categorical(list(val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwdFyIBCTVLn"
      },
      "outputs": [],
      "source": [
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(64,(1,3),1,activation='relu',padding='same',kernel_regularizer=tensorflow.keras.regularizers.l2(l=0.001),input_shape=(train_data.shape[1],train_data.shape[2],train_data.shape[3])))\n",
        "cnn.add(Conv2D(16,(2,3),1,activation='relu',padding='same',kernel_regularizer=tensorflow.keras.regularizers.l2(l=0.001)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(128,activation='relu'))\n",
        "cnn.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qr0R53w1VGh7"
      },
      "outputs": [],
      "source": [
        "cnn.compile(loss='categorical_crossentropy',optimizer=tensorflow.keras.optimizers.Adam(0.0005,),metrics=['accuracy'])\n",
        "cnn.fit(train_data,train_labels,batch_size=64,epochs=100,validation_data=(val_data,val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM_8JcuAXzWj"
      },
      "source": [
        "#Vanella RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxFjH8bdXBoZ"
      },
      "outputs": [],
      "source": [
        "# to fit in RNN input\n",
        "train_data = np.transpose(train_data, (0, 2, 1))\n",
        "test_data = np.transpose(test_data, (0, 2, 1))\n",
        "val_data = np.transpose(val_data, (0, 2, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6YFsbecXCI_"
      },
      "outputs": [],
      "source": [
        "# feature minMax normalization\n",
        "train_data = train_data.reshape(len(train_data),-1)\n",
        "test_data = test_data.reshape(len(test_data),-1)\n",
        "val_data = val_data.reshape(len(val_data),-1)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "train_data = scaler.fit_transform(train_data)\n",
        "test_data = scaler.transform(test_data)\n",
        "val_data = scaler.transform(val_data)\n",
        "\n",
        "train_data = train_data.reshape(len(train_data),128,4)\n",
        "test_data = test_data.reshape(len(test_data),128,4)\n",
        "val_data = val_data.reshape(len(val_data),128,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfM1ydN4XE0l",
        "outputId": "968d74b4-8cca-4d0d-9959-840aac124fab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((798000, 128, 4), (360000, 128, 4), (42000, 128, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "train_data.shape, test_data.shape, val_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edTWaAAAXG-N"
      },
      "outputs": [],
      "source": [
        "def RNN_model():\n",
        "  rnn=Sequential()\n",
        "  rnn.add(SimpleRNN(100,input_shape=(128,4),return_sequences=True))\n",
        "  rnn.add(SimpleRNN(100,return_sequences=True))\n",
        "  rnn.add(SimpleRNN(50))\n",
        "  rnn.add(Dense(10,activation='softmax'))\n",
        "  return rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgDmdRYuXJ_y"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "rnn = RNN_model()\n",
        "rnn.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YOVeIHYYNvW"
      },
      "outputs": [],
      "source": [
        "#load model\n",
        "rnn = load_model('/content/drive/MyDrive/Colab Notebooks/PR lab4/partly_trained5.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKciZs8P6L-5"
      },
      "outputs": [],
      "source": [
        "#save model\n",
        "rnn.save('/content/drive/MyDrive/Colab Notebooks/PR lab4/partly_trained5.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gebltc_BYAW-"
      },
      "outputs": [],
      "source": [
        "#train for one epoch\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "for i in range(100):\n",
        "  rnn.fit(train_data,train_labels,batch_size=64,epochs=1,validation_data=(val_data,val_labels), callbacks=[callback])\n",
        "  #save model\n",
        "  rnn.save('/content/drive/MyDrive/Colab Notebooks/PR lab4/partly_trained5.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0duj4CCiAGSH"
      },
      "source": [
        "#LSTM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1phAzu2mFWNo"
      },
      "outputs": [],
      "source": [
        "# to fit in LSTM input\n",
        "train_data = np.transpose(train_data, (0, 2, 1))\n",
        "test_data = np.transpose(test_data, (0, 2, 1))\n",
        "val_data = np.transpose(val_data, (0, 2, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8fG6-26Z2ir"
      },
      "outputs": [],
      "source": [
        "# feature minMax normalization\n",
        "train_data = train_data.reshape(len(train_data),-1)\n",
        "test_data = test_data.reshape(len(test_data),-1)\n",
        "val_data = val_data.reshape(len(val_data),-1)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "train_data = scaler.fit_transform(train_data)\n",
        "test_data = scaler.transform(test_data)\n",
        "val_data = scaler.transform(val_data)\n",
        "\n",
        "train_data = train_data.reshape(len(train_data),128,4)\n",
        "test_data = test_data.reshape(len(test_data),128,4)\n",
        "val_data = val_data.reshape(len(val_data),128,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDwN9malbdcO",
        "outputId": "91e252b8-dee4-4053-b263-42b687fdd261"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((798000, 128, 4), (360000, 128, 4), (42000, 128, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_data.shape, test_data.shape, val_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mEkzZBnABr8"
      },
      "outputs": [],
      "source": [
        "def LSTM_model():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, unroll=True, input_shape=(128,4))) # 3D\n",
        "  model.add(LSTM(100, return_sequences=True, unroll=True))\n",
        "  model.add(LSTM(50, unroll=True))\n",
        "  model.add(Dense(10,activation='softmax'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpkfQWwDBaB_"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "lstm = LSTM_model()\n",
        "lstm.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001, decay=1e-6), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDaGwsb6TVSw"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "lstm.save('/content/drive/MyDrive/Colab Notebooks/PR lab4/partly_trained14.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6A8GVatSDdo"
      },
      "outputs": [],
      "source": [
        "#load model\n",
        "lstm = load_model('/content/drive/MyDrive/Colab Notebooks/PR lab4/partly_trained14.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCpeUePBEBeB"
      },
      "outputs": [],
      "source": [
        "lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GgjnrwESFup"
      },
      "outputs": [],
      "source": [
        "#train for one epoch\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "for i in range(100):\n",
        "  lstm.fit(train_data,train_labels,batch_size=64,epochs=1,validation_data=(val_data,val_labels), callbacks=[callback])\n",
        "  #save model\n",
        "  lstm.save('/content/drive/MyDrive/Colab Notebooks/PR lab4/partly_trained14.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojv_2tNE1An7"
      },
      "source": [
        "# Bonus - CNN-LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWa6v8dj3-S0"
      },
      "outputs": [],
      "source": [
        "# to fit in LSTM input\n",
        "train_data = np.transpose(train_data, (0, 2, 1))\n",
        "test_data = np.transpose(test_data, (0, 2, 1))\n",
        "val_data = np.transpose(val_data, (0, 2, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03kgnU7Y4E1M"
      },
      "outputs": [],
      "source": [
        "# feature minMax normalization\n",
        "train_data = train_data.reshape(len(train_data),-1)\n",
        "test_data = test_data.reshape(len(test_data),-1)\n",
        "val_data = val_data.reshape(len(val_data),-1)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "train_data = scaler.fit_transform(train_data)\n",
        "test_data = scaler.transform(test_data)\n",
        "val_data = scaler.transform(val_data)\n",
        "\n",
        "train_data = train_data.reshape(len(train_data),128,4)\n",
        "test_data = test_data.reshape(len(test_data),128,4)\n",
        "val_data = val_data.reshape(len(val_data),128,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm8HUznS9r9S"
      },
      "outputs": [],
      "source": [
        "train_data=train_data.reshape((train_data.shape[0],1,train_data.shape[1],train_data.shape[2]))\n",
        "test_data=test_data.reshape((test_data.shape[0],1,test_data.shape[1],test_data.shape[2]))\n",
        "val_data=val_data.reshape((val_data.shape[0],1,val_data.shape[1],val_data.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AfqdLST9tRL",
        "outputId": "20728f97-f616-4087-88d4-cfb27ce3ec06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(798000, 1, 128, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoQpAd5D1Qwy"
      },
      "outputs": [],
      "source": [
        "def cnn_lstm_model():\n",
        "  cnn_lstm_model = Sequential()\n",
        "  cnn_lstm_model.add(TimeDistributed(Conv1D(filters=64,kernel_size=4,activation='relu'),input_shape=(1,128,4)))\n",
        "  cnn_lstm_model.add(TimeDistributed(MaxPool1D(pool_size= 2, strides=2)))\n",
        "  cnn_lstm_model.add(TimeDistributed(Flatten()))\n",
        "  cnn_lstm_model.add(LSTM(32, dropout = 0.3, recurrent_dropout = 0.3))\n",
        "  cnn_lstm_model.add(Dense(10, activation = 'sigmoid'))\n",
        "  return cnn_lstm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2973DZ1c4WaQ",
        "outputId": "d358c12f-594a-4b0e-a003-4c54e1690253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "cnn_lstm = cnn_lstm_model()\n",
        "cnn_lstm.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_lstm = load_model('/content/drive/MyDrive/Colab Notebooks/PR lab4/partly_trained43.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyqq-K3rnWaW",
        "outputId": "3c355045-9e38-46c0-9d45-bf5af64732d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxqPdJy-4bod"
      },
      "outputs": [],
      "source": [
        "#train for one epoch\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "for i in range(100):\n",
        "  cnn_lstm.fit(train_data,train_labels,batch_size=64,epochs=1,validation_data=(val_data,val_labels), callbacks=[callback])\n",
        "  #save model\n",
        "  cnn_lstm.save('/content/drive/MyDrive/Colab Notebooks/PR lab4/partly_trained43.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_xlAl-jR1iN"
      },
      "source": [
        "# Big picture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWT_DKMuKQoD"
      },
      "outputs": [],
      "source": [
        "def overall_test(model, test_data, test_labels):\n",
        "    # overall test results\n",
        "    h, overall_acc = model.evaluate(test_data, test_labels)\n",
        "    print('overall_acc : ', overall_acc)\n",
        "\n",
        "    \n",
        "    y_prob = model.predict(test_data) \n",
        "    y_pred = y_prob.argmax(axis=-1)\n",
        "\n",
        "    overall_c = confusion_matrix(test_labels, y_pred)\n",
        "    print('overall_confusion :\\n', overall_c)\n",
        "\n",
        "    return overall_acc, overall_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SsEKsGD8Dmm"
      },
      "outputs": [],
      "source": [
        "# big picture\n",
        "def big_picture(model, old_test_labels, test_data, test_labels):\n",
        "  #sort \n",
        "  sort_indices = old_test_labels[:, 1].astype('int').argsort()\n",
        "  old_test_labels = old_test_labels[sort_indices]\n",
        "  test_data = test_data[sort_indices]\n",
        "  test_labels = test_labels[sort_indices]\n",
        "\n",
        "  #split\n",
        "  temp = old_test_labels[:,1].astype('float64')\n",
        "  split_indices = np.where(np.diff(temp))[0]+1\n",
        "  splitted_test_data = np.split(test_data, split_indices)\n",
        "  splitted_test_labels = np.split(test_labels, split_indices)\n",
        "  \n",
        "  # test results per snr\n",
        "  snr = np.unique(old_test_labels[:,1].astype('int')).tolist()\n",
        "  acc = []\n",
        "  conf = []\n",
        "  for data, labels in zip(splitted_test_data, splitted_test_labels):\n",
        "    h, a = model.evaluate(data, labels)\n",
        "    acc.append(a)\n",
        "\n",
        "    y_prob = model.predict(data) \n",
        "    y_pred = y_prob.argmax(axis=-1)\n",
        "\n",
        "    c = confusion_matrix(labels, y_pred)\n",
        "    conf.append(c)\n",
        "\n",
        "  return snr, acc, conf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK5fmLQLgrA3"
      },
      "outputs": [],
      "source": [
        "def plot_conf(cf_matrix):\n",
        "  labels = [\"8PSK\",\"AM-DSB\",\"BPSK\",\"CPFSK\",\"GFSK\",\"PAM4\",\"QAM16\",\"QAM64\",\"QPSK\",\"WBFM\"]\n",
        "  plt.rcParams[\"figure.figsize\"] = (15,15)\n",
        "\n",
        "  ax = sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "\n",
        "  ax.set_title('Confusion Matrix\\n\\n');\n",
        "  ax.set_xlabel('\\nPredicted')\n",
        "  ax.set_ylabel('Actual');\n",
        "\n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vxJOugNj4om"
      },
      "outputs": [],
      "source": [
        "def plot_snr(snr, acc):\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "  plt.plot(snr, acc)\n",
        "  plt.xlabel('snr')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.grid(color = 'lime', linestyle = '--', linewidth = 0.5)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_acc, overall_c = overall_test(cnn_lstm, test_data, test_labels)"
      ],
      "metadata": {
        "id": "XpIKKP0M5F5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7fKZuRIM6tq"
      },
      "outputs": [],
      "source": [
        "snr, acc, conf  = big_picture(cnn_lstm, old_test_labels, test_data, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcYTMKJmGhT_"
      },
      "outputs": [],
      "source": [
        "plot_conf(overall_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tslMmpd2rQGV"
      },
      "outputs": [],
      "source": [
        "plot_snr(snr, acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snr, acc, conf"
      ],
      "metadata": {
        "id": "n0TXtmz_Clty"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UasqP4K7Xss2"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}